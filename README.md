# Customer Segmentation Using Clustering Models on Bank Personal Loan Data

ğŸ”§ Data Preprocessing Steps
Look at the basics Check descriptive stats to understand the data ğŸ“Š

Drop what's not needed Remove unnecessary columns ğŸ—‘ï¸

Label the categories Convert categorical columns to numbers using Label Encoder ğŸ”¢

Find the blanks Check for missing values and handle them accordingly â“

Outlier check Use the IQR method to cap outliers â€” but only for columns with more than 2 unique values ğŸš«ğŸ“ˆ

Visual check Plot a scatter plot between Income and CCAvg to spot patterns or weirdness ğŸ¯

Standardize it Apply standardization to scale the data âš–ï¸



ğŸ¤– Modeling with K-Means
Start simple Train a KMeans model using default settings ğŸ¯

Find the best number of clusters

Calculate WCSS (within-cluster sum of squares) for 1 to 7 clusters

Calculate Silhouette score to measure quality ğŸ§ 

Use KneeLocator to find the "elbow" = best number of clusters (that sweet spot) ğŸ’¡

Build the final model Use your chosen number of clusters to fit a new KMeans model âœ…

Predict clusters Add a new column Segment_KM with the cluster predictions ğŸ”¢

Explore the clusters Use groupby('Segment_KM') to analyze the characteristics of each group ğŸ”

Visualize it! Plot a scatter between Income and CCAvg, color-coded by Segment_KM ğŸ¨


  
ğŸ¯ K-Means with PCA â€“ Step-by-Step
Apply PCA on the scaled data Fit a PCA() model and get the explained variance ratio for each principal component ğŸ“Š

Pick number of components Plot the cumulative explained variance â€” choose components that together explain at least 80% of the variance (best practice!) âœ…

Rebuild PCA Fit PCA(n_components=chosen_number) on the scaled data again to reduce the dimensionality ğŸ’¡

Understand what each component means Create a dataframe with PCA components (rows) Ã— original variables (columns) to see which component relates to what ğŸ§ 

Calculate PCA scores Get the transformed data (letâ€™s call it scores_pca) â¡ï¸ This is the data in the new PCA space

Wrap it up in a new dataframe Create pca_df and rename new PCA features as Variable_1, Variable_2, etc ğŸ§¾

Run K-Means again

Calculate WCSS and Silhouette Score for clusters from 1 to 7

Use KneeLocator to find the elbow (best number of clusters) ğŸ¯

Build final KMeans model using that cluster number

Predict clusters Add a new column Segment_KM_PCA with predicted cluster labels ğŸ”¢

Merge original and PCA data Combine data and pca_df into one final dataframe ğŸ“

Visualize in 2D Plot a scatter between Variable_1 and Variable_2, colored by Segment_KM_PCA ğŸ¨


ğŸŒ¿ Hierarchical Clustering (Agglomerative)
Draw the dendrogram Use linkage and dendrogram to visualize clusters â€” itâ€™ll help you decide the number of clusters (centroids) ğŸŒ³âœ¨

Fit the model Build the AgglomerativeClustering model using the number of clusters you picked ğŸ‘Œ

Predict clusters Add a new column named segment_HC with the predicted cluster labels ğŸ§©

Visualize it Plot a scatter between Income and CCAvg, colored by segment_HC ğŸ¨ğŸ’¼


ğŸ§¬ Agglomerative Clustering (PCA Version)
Draw the dendrogram Use the pca_df (your PCA-transformed data) to build a dendrogram â€” this helps you decide how many clusters to use ğŸŒ³

Build the model Create the AgglomerativeClustering model using the number of clusters you chose âœ…

Predict the clusters Add a new column named segment_HC_PCA with the predicted cluster labels ğŸ§©

Visualize the result Plot a scatter plot between Variable_1 and Variable_2, coloring the points by segment_HC_PCA ğŸ¨
